[build-system]
requires = ["setuptools>=61.2"]
build-backend = "setuptools.build_meta"

[project]
name = "kedro-datasets"
authors = [
    {name = "Kedro"}
]
description = "Kedro-Datasets is where you can find all of Kedro's data connectors."
requires-python = ">=3.10"
license = {text = "Apache Software License (Apache 2.0)"}
dependencies = [
    "kedro>=1.0.0rc1, <2.0.0",
    "lazy_loader",
]
dynamic = ["readme", "version"]

[project.optional-dependencies]
pandas-base = ["pandas>=1.3, <3.0"]
spark-base = ["pyspark>=2.2, <4.0"]
hdfs-base = ["hdfs>=2.5.8, <3.0"]
s3fs-base = ["s3fs>=2021.4"]
polars-base = ["polars>=0.18.0"]
plotly-base = ["plotly>=4.8.0, <6.0"]
delta-base = ["delta-spark>=1.0, <4.0"]
networkx-base = ["networkx~=3.4"]

# Individual Datasets
api-apidataset = ["requests~=2.20"]
api = ["kedro-datasets[api-apidataset]"]

biosequence-biosequencedataset = ["biopython~=1.73"]
biosequence = ["kedro-datasets[biosequence-biosequencedataset]"]

dask-csvdataset = ["dask[dataframe]>=2021.10"]
dask-parquetdataset = ["dask[complete]>=2021.10", "triad>=0.6.7, <1.0"]
dask = ["kedro-datasets[dask-parquetdataset, dask-csvdataset]"]

databricks-managedtabledataset = ["kedro-datasets[hdfs-base,s3fs-base]"]
databricks = ["kedro-datasets[databricks-managedtabledataset]"]

geopandas-genericdataset = ["geopandas>=0.8.0, <2.0", "fiona>=1.8, <2.0"]
geopandas = ["kedro-datasets[geopandas-genericdataset]"]

holoviews-holoviewswriter = ["holoviews>=1.13.0"]
holoviews = ["kedro-datasets[holoviews-holoviewswriter]"]

huggingface-hfdataset = ["datasets", "huggingface_hub"]
huggingface-hftransformerpipelinedataset = ["transformers"]
huggingface = ["kedro-datasets[huggingface-hfdataset,huggingface-hftransformerpipelinedataset]"]

ibis-athena = ["ibis-framework[athena]"]
ibis-bigquery = ["ibis-framework[bigquery]"]
ibis-clickhouse = ["ibis-framework[clickhouse]"]
ibis-dask = ["ibis-framework[dask]<10.0"]
ibis-databricks = ["ibis-framework[databricks]"]
ibis-datafusion = ["ibis-framework[datafusion]"]
ibis-druid = ["ibis-framework[druid]"]
ibis-duckdb = ["ibis-framework[duckdb]"]
ibis-exasol = ["ibis-framework[exasol]"]
ibis-flink = ["ibis-framework", "apache-flink"]
ibis-impala = ["ibis-framework[impala]"]
ibis-mssql = ["ibis-framework[mssql]"]
ibis-mysql = ["ibis-framework[mysql]"]
ibis-oracle = ["ibis-framework[oracle]"]
ibis-pandas = ["ibis-framework[pandas]<10.0"]
ibis-polars = ["ibis-framework[polars]"]
ibis-postgres = ["ibis-framework[postgres]"]
ibis-pyspark = ["ibis-framework[pyspark]"]
ibis-risingwave = ["ibis-framework[risingwave]"]
ibis-snowflake = ["ibis-framework[snowflake]"]
ibis-sqlite = ["ibis-framework[sqlite]"]
ibis-trino = ["ibis-framework[trino]"]
ibis = ["ibis-framework"]

json-jsondataset = []
json = ["kedro-datasets[json-jsondataset]"]

matlab-matlabdataset = ["scipy"]
matlab = ["kedro-datasets[matlab-matlabdataset]"]

matplotlib-matplotlibwriter = ["matplotlib>=3.0.3, <4.0"]
matplotlib-matplotlibdataset = ["matplotlib>=3.0.3, <4.0"]
matplotlib = ["kedro-datasets[matplotlib-matplotlibwriter,matplotlib-matplotlibdataset]"]

networkx-gmldataset = ["kedro-datasets[networkx-base]"]
networkx-graphmldataset = ["kedro-datasets[networkx-base]"]
networkx-jsondataset = ["kedro-datasets[networkx-base]"]
networkx = ["kedro-datasets[networkx-base]"]

openxml-docxdataset = ["python-docx"]
openxml = ["kedro-datasets[openxml-docxdataset]"]

optuna-studydataset = ["optuna"]
optuna = ["kedro-datasets[optuna-studydataset]"]

pandas-csvdataset = ["kedro-datasets[pandas-base]"]
pandas-deltatabledataset = ["kedro-datasets[pandas-base]", "deltalake>=0.10.0, <1.0.0"]
pandas-exceldataset = ["kedro-datasets[pandas-base]", "openpyxl>=3.0.6, <4.0"]
pandas-featherdataset = ["kedro-datasets[pandas-base]"]
pandas-gbqtabledataset = ["kedro-datasets[pandas-base]", "pandas-gbq>=0.12.0"]
pandas-gbqquerydataset = ["kedro-datasets[pandas-base]", "pandas-gbq>=0.12.0"]
pandas-genericdataset = ["kedro-datasets[pandas-base]"]
pandas-hdfdataset = ["kedro-datasets[pandas-base]", "tables>=3.6"]
pandas-jsondataset = ["kedro-datasets[pandas-base]"]
pandas-parquetdataset = ["kedro-datasets[pandas-base]", "pyarrow>=6.0"]
pandas-sqltabledataset = ["kedro-datasets[pandas-base]", "SQLAlchemy>=1.4, <3.0"]
pandas-sqlquerydataset = ["kedro-datasets[pandas-base]", "SQLAlchemy>=1.4, <3.0", "pyodbc>=4.0"]
pandas-xmldataset = ["kedro-datasets[pandas-base]", "lxml~=4.6"]
pandas = [
    """kedro-datasets[pandas-csvdataset,\
    pandas-deltatabledataset,\
    pandas-exceldataset,\
    pandas-featherdataset,\
    pandas-gbqquerydataset,\
    pandas-gbqtabledataset,\
    pandas-genericdataset,\
    pandas-hdfdataset,\
    pandas-jsondataset,\
    pandas-parquetdataset,\
    pandas-sqltabledataset,\
    pandas-sqlquerydataset,\
    pandas-xmldataset]"""
]

pickle-pickledataset = ["compress-pickle[lz4]~=2.1.0"]
pickle = ["kedro-datasets[pickle-pickledataset]"]

pillow-imagedataset = ["Pillow>=9.0"]
pillow = ["kedro-datasets[pillow-imagedataset]"]

plotly-htmldataset = ["kedro-datasets[plotly-base]"]
plotly-jsondataset = ["kedro-datasets[plotly-base]"]
plotly-plotlydataset = ["kedro-datasets[pandas-base,plotly-base]"]
plotly = ["kedro-datasets[plotly-htmldataset,plotly-jsondataset,plotly-plotlydataset]"]

polars-csvdataset = ["kedro-datasets[polars-base]"]
polars-eagerpolarsdataset = ["kedro-datasets[polars-base]", "pyarrow>=4.0", "xlsx2csv>=0.8.0", "deltalake >= 0.6.2, <1.0.0"]
polars-lazypolarsdataset = ["kedro-datasets[polars-base]", "pyarrow>=4.0", "deltalake >= 0.6.2, <1.0.0"]
polars = [
    """kedro-datasets[polars-csvdataset,\
    polars-eagerpolarsdataset,\
    polars-lazypolarsdataset]"""
]

redis-pickledataset = ["redis~=4.1"]
redis = ["kedro-datasets[redis-pickledataset]"]

snowflake-snowparktabledataset = ["snowflake-snowpark-python>=1.23"]
snowflake = ["kedro-datasets[snowflake-snowparktabledataset]"]

spark-deltatabledataset = ["kedro-datasets[spark-base,hdfs-base,s3fs-base,delta-base]"]
spark-sparkdataset = ["kedro-datasets[spark-base,hdfs-base,s3fs-base]"]
spark-sparkhivedataset = ["kedro-datasets[spark-base,hdfs-base,s3fs-base]"]
spark-sparkjdbcdataset = ["kedro-datasets[spark-base]"]
spark-sparkstreamingdataset = ["kedro-datasets[spark-base,hdfs-base,s3fs-base]"]
spark = [
    """kedro-datasets[spark-deltatabledataset,\
    spark-sparkdataset,\
    spark-sparkhivedataset,\
    spark-sparkjdbcdataset,\
    spark-sparkstreamingdataset]"""
]

svmlight-svmlightdataset = ["scikit-learn>=1.0.2", "scipy>=1.7.3"]
svmlight = ["kedro-datasets[svmlight-svmlightdataset]"]

tensorflow-tensorflowmodeldataset = ["tensorflow~=2.0; platform_system != 'Darwin' or platform_machine != 'arm64'", "tensorflow-macos~=2.0; platform_system == 'Darwin' and platform_machine == 'arm64'"]
tensorflow = ["kedro-datasets[tensorflow-tensorflowmodeldataset]"]

text-textdataset = []
text = ["kedro-datasets[text-textdataset]"]

yaml-yamldataset = ["kedro-datasets[pandas-base]", "PyYAML>=4.2, <7.0"]
yaml = ["kedro-datasets[yaml-yamldataset]"]

# Experimental Datasets
darts-torch-model-dataset = ["u8darts-all"]
darts = ["kedro-datasets[darts-torch-model-dataset]"]
databricks-externaltabledataset = ["kedro-datasets[hdfs-base,s3fs-base]"]
langchain-chatopenaidataset = ["langchain-openai~=0.1.7"]
langchain-openaiembeddingsdataset = ["langchain-openai~=0.1.7"]
langchain-chatanthropicdataset = ["langchain-anthropic~=0.1.13", "langchain-community~=0.2.0"]
langchain-chatcoheredataset = ["langchain-cohere~=0.1.5", "langchain-community~=0.2.0"]
langchain = ["kedro-datasets[langchain-chatopenaidataset,langchain-openaiembeddingsdataset,langchain-chatanthropicdataset,langchain-chatcoheredataset]"]

netcdf-netcdfdataset = ["h5netcdf>=1.2.0","netcdf4>=1.6.4","xarray>=2023.1.0"]
netcdf = ["kedro-datasets[netcdf-netcdfdataset]"]

prophet-dataset = ["prophet>=1.1.5"]
prophet = ["kedro-datasets[prophet]"]
pytorch-dataset = ["torch"]
pytorch = ["kedro-datasets[pytorch-dataset]"]

rioxarray-geotiffdataset = ["rioxarray>=0.15.0"]
rioxarray = ["kedro-datasets[rioxarray-geotiffdataset]"]

safetensors-safetensorsdataset = ["safetensors", "numpy"]
safetensors = ["kedro-datasets[safetensors-safetensorsdataset]"]

video-videodataset = ["opencv-python~=4.5.5.64"]
video = ["kedro-datasets[video-videodataset]"]

# Docs requirements
docs = [
   "mkdocs>=1.6.1",
   "mkdocs-material>=9.6.11",
   "mkdocs-material-extensions>=1.3.1",
   "mkdocs-mermaid2-plugin>=1.2.1",
   "mkdocs-autorefs>=1.4.1",
   "mkdocs-get-deps>=0.2.0",
   "mkdocstrings>=0.29.1",
   "mkdocstrings-python>=0.29.1",
   "linkchecker>=10.2.1",
   "ipykernel>=5.3, <7.0",
   "Jinja2<3.2.0"
]

# Test requirements
test = [
    "accelerate<0.32",  # Temporary pin
    "adlfs~=2023.1",
    "behave==1.2.6",
    "biopython~=1.73",
    "cloudpickle~=2.2.1",
    "compress-pickle[lz4]~=2.1.0",
    "coverage>=7.2.0",
    "dask[complete]>=2021.10",
    "delta-spark>=1.0, <3.0",
    "deltalake>=0.10.0, <1.0.0",
    "dill~=0.3.1",
    "filelock>=3.4.0, <4.0",
    "fiona >=1.8, <2.0",
    "gcsfs>=2023.1, <2023.3",
    "geopandas>=0.8.0, <2.0",
    "hdfs>=2.5.8, <3.0",
    "holoviews>=1.13.0",
    "ibis-framework[duckdb,examples]",
    "ipython>=7.31.1, <8.0",
    "Jinja2<3.2.0",
    "joblib>=0.14",
    "jupyterlab>=3.0",
    "jupyter~=1.0",
    "lxml~=4.6",
    "matplotlib>=3.5, <4.0",
    "memory_profiler>=0.50.0, <1.0",
    "moto==5.0.0",
    "networkx~=3.4",
    "openpyxl>=3.0.3, <4.0",
    "pandas-gbq>=0.12.0",
    "pandas>=2.0",
    "Pillow~=10.0",
    "plotly>=4.8.0, <6.0",
    "polars[deltalake,xlsx2csv]>=1.0",
    "pyarrow>=1.0; python_version < '3.11'",
    "pyarrow>=7.0; python_version >= '3.11'",  # Adding to avoid numpy build errors
    "pyodbc~=5.0",
    "pyspark>=3.0; python_version < '3.11'",
    "pyspark>=3.4; python_version >= '3.11'",
    "pytest-cov~=3.0",
    "pytest-mock>=1.7.1, <2.0",
    "pytest-xdist[psutil]~=2.2.1",
    "pytest~=7.2",
    "python-docx",
    "redis~=4.1",
    "requests-mock~=1.6",
    "requests~=2.20",
    "s3fs>=2021.04",
    "snowflake-snowpark-python>=1.23; python_version < '3.12'",
    "scikit-learn>=1.0.2,<2",
    "scipy>=1.7.3",
    "packaging",
    "pyOpenSSL>=22.1.0",  # Workaround for incorrect pin in the snowflake-connector-python package; see https://github.com/snowflakedb/snowflake-connector-python/issues/2109
    "SQLAlchemy>=1.2",
    "tables>=3.6",
    "tensorflow-macos~=2.0; platform_system == 'Darwin' and platform_machine == 'arm64'",
    "tensorflow~=2.0; platform_system != 'Darwin' or platform_machine != 'arm64'",
    "triad>=0.6.7, <1.0",
    "xarray>=2023.1.0",
    "xlsxwriter~=1.0",
    # huggingface
    "datasets",
    "huggingface_hub",
    "transformers[torch]",
]

# Lint requirements
lint = [
    "bandit>=1.6.2, <2.0",
    "blacken-docs==1.9.2",
    "black~=22.0",
    "detect-secrets~=1.5.0",
    "import-linter[toml]==1.2.6",
    "mypy~=1.0",
    "pre-commit>=2.9.2",
    "ruff~=0.12.1",
    # mypy related dependencies
    "types-cachetools",
    "types-PyYAML",
    "types-redis",
    "types-requests",
    "types-decorator",
    "types-six",
    "types-tabulate",
]

# Experimental dataset requirements
experimental = [
    "langchain-openai",
    "langchain-cohere",
    "langchain-anthropic",
    "langchain-community",
    "h5netcdf>=1.2.0",
    "netcdf4>=1.6.4",
    "xarray>=2023.1.0",
    "rioxarray",
    "torch",
    "opencv-python~=4.5.5.64",
    "prophet>=1.1.5",
    "optuna",
    "u8darts[all]",
]

# All requirements
all = ["kedro-datasets[test,docs,lint]"]

[project.urls]
Source = "https://github.com/kedro-org/kedro-plugins/tree/main/kedro-datasets"
Documentation = "https://docs.kedro.org"
Tracker = "https://github.com/kedro-org/kedro-plugins/issues"

[tool.setuptools.packages.find]
include = ["kedro_datasets*"]

[tool.setuptools.dynamic]
readme = {file = "README.md", content-type = "text/markdown"}
version = {attr = "kedro_datasets.__version__"}

[tool.coverage.report]
fail_under = 100
show_missing = true
# temporarily ignore kedro_datasets/__init__.py in coverage report
omit = ["tests/*", "kedro_datasets/holoviews/*", "kedro_datasets/tensorflow/*", "kedro_datasets/databricks/*", "kedro_datasets/snowflake/*", "kedro_datasets/__init__.py", "kedro_datasets/conftest.py", "*/__init__.py"]
exclude_also = ["raise NotImplementedError", "if TYPE_CHECKING:"]

[tool.pytest.ini_options]
addopts = [
    "--cov-report=xml:coverage.xml",
    "--cov-report=term-missing",
    "--cov=kedro_datasets",
    "--cov=tests",
    "--ignore=tests/template/fake_repo",
    "--no-cov-on-fail",
    "-ra",
    "-W",
    "ignore"
]

[tool.ruff]
line-length = 88
show-fixes = true

[tool.ruff.lint]
select = [
    "F",   # Pyflakes
    "W",   # pycodestyle
    "E",   # pycodestyle
    "I",   # isort
    "UP",  # pyupgrade
    "PL",  # Pylint
    "T201", # Print Statement
]
ignore = ["E501", "F401"]  # Black takes care of line-too-long

[tool.ruff.per-file-ignores]
"{tests,docs,kedro_datasets_experimental/tests}/*" = ["PLR2004", "PLR0913", "T201"]
"*/{__init__.py}" = ["F821"] # temporarily ignore ruff undefined name errors for dataset aliases

[tool.mypy]
ignore_missing_imports = true
disable_error_code = ['no-redef']
